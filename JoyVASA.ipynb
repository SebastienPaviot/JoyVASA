{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMf9Wu3TH80lwo+Xx/KW2uF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SebastienPaviot/JoyVASA/blob/main/JoyVASA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "B1FeejysVlWW",
        "outputId": "3deefa39-af8d-4002-d325-bcf2a57ce90b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'JoyVASA' already exists and is not an empty directory.\n",
            "/content/JoyVASA\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (1.1.1)\n",
            "Requirement already satisfied: audio-separator in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.25.1)\n",
            "Requirement already satisfied: av in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (14.0.1)\n",
            "Requirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.45.0)\n",
            "Requirement already satisfied: decord in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.31.0)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (0.8.0)\n",
            "Requirement already satisfied: insightface in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.7.3)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.10.2.post1)\n",
            "Requirement already satisfied: mlflow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (2.19.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (1.26.4)\n",
            "Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.3.0)\n",
            "Requirement already satisfied: onnx2torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (1.5.15)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (1.17.0)\n",
            "Requirement already satisfied: onnxruntime-gpu in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (1.20.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (4.10.0.84)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (11.0.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (75.1.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (2.4.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (0.19.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 24)) (4.66.6)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 25)) (4.46.3)\n",
            "Requirement already satisfied: xformers in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 26)) (0.0.28.post1)\n",
            "Requirement already satisfied: isort in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 27)) (5.13.2)\n",
            "Requirement already satisfied: pylint in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 28)) (3.3.2)\n",
            "Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 29)) (4.0.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 30)) (1.13.1)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 31)) (2.36.1)\n",
            "Requirement already satisfied: lmdb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 32)) (1.5.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 33)) (13.9.4)\n",
            "Requirement already satisfied: ffmpeg-python in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 34)) (0.2.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 35)) (0.24.0)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 36)) (1.4.20)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 37)) (3.8.0)\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 38)) (0.5.1)\n",
            "Requirement already satisfied: tyro in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 39)) (0.9.2)\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 40)) (5.9.0)\n",
            "Requirement already satisfied: pykalman in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 41)) (0.9.7)\n",
            "Requirement already satisfied: mediapipe[vision] in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.10.20)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.26.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from accelerate->-r requirements.txt (line 1)) (0.4.5)\n",
            "Requirement already satisfied: beartype<0.19.0,>=0.18.5 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.18.5)\n",
            "Requirement already satisfied: diffq>=0.2 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.2.4)\n",
            "Requirement already satisfied: julius>=0.2 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.2.7)\n",
            "Requirement already satisfied: ml_collections in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: pydub>=0.25 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.25.1)\n",
            "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (2.32.3)\n",
            "Requirement already satisfied: resampy>=0.4 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.4.3)\n",
            "Requirement already satisfied: rotary-embedding-torch<0.7.0,>=0.6.1 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.6.5)\n",
            "Requirement already satisfied: samplerate==0.1.0 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (0.1.0)\n",
            "Requirement already satisfied: six>=1.16 in /usr/local/lib/python3.10/dist-packages (from audio-separator->-r requirements.txt (line 2)) (1.17.0)\n",
            "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from samplerate==0.1.0->audio-separator->-r requirements.txt (line 2)) (1.17.1)\n",
            "Requirement already satisfied: typing_extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from bitsandbytes->-r requirements.txt (line 4)) (4.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 6)) (8.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 6)) (3.16.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from diffusers->-r requirements.txt (line 6)) (2024.9.11)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface->-r requirements.txt (line 8)) (1.5.2)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface->-r requirements.txt (line 8)) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface->-r requirements.txt (line 8)) (3.0.11)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface->-r requirements.txt (line 8)) (3.12.0)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (3.0.1)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (1.4.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (0.60.0)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (1.8.2)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (0.5.0.post1)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (0.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa->-r requirements.txt (line 9)) (1.1.0)\n",
            "\u001b[33mWARNING: mediapipe 0.10.20 does not provide the extra 'vision'\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (24.2.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (24.3.25)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (0.4.33)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (0.4.33)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (4.10.0.84)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (4.25.5)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from mediapipe[vision]->-r requirements.txt (line 10)) (0.2.0)\n",
            "Requirement already satisfied: mlflow-skinny==2.19.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (2.19.0)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (3.0.3)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (3.1.4)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (1.14.0)\n",
            "Requirement already satisfied: docker<8,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (7.1.0)\n",
            "Requirement already satisfied: graphene<4 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (3.4.3)\n",
            "Requirement already satisfied: gunicorn<24 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (23.0.0)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (3.7)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<19,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (17.0.0)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow->-r requirements.txt (line 11)) (2.0.36)\n",
            "Requirement already satisfied: cachetools<6,>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (3.1.0)\n",
            "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (0.39.0)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (3.1.43)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (1.28.2)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (1.28.2)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (0.5.3)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 12)) (0.1.10)\n",
            "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/dist-packages (from omegaconf->-r requirements.txt (line 14)) (4.9.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 17)) (15.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu->-r requirements.txt (line 17)) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (3.4.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (12.1.105)\n",
            "Requirement already satisfied: triton==3.0.0 in /usr/local/lib/python3.10/dist-packages (from torch->-r requirements.txt (line 22)) (3.0.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->-r requirements.txt (line 22)) (12.6.85)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers->-r requirements.txt (line 25)) (0.20.3)\n",
            "Requirement already satisfied: dill>=0.2 in /usr/local/lib/python3.10/dist-packages (from pylint->-r requirements.txt (line 28)) (0.3.9)\n",
            "Requirement already satisfied: platformdirs>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pylint->-r requirements.txt (line 28)) (4.3.6)\n",
            "Requirement already satisfied: astroid<=3.4.0-dev0,>=3.3.5 in /usr/local/lib/python3.10/dist-packages (from pylint->-r requirements.txt (line 28)) (3.3.6)\n",
            "Requirement already satisfied: mccabe<0.8,>=0.6 in /usr/local/lib/python3.10/dist-packages (from pylint->-r requirements.txt (line 28)) (0.7.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from pylint->-r requirements.txt (line 28)) (2.2.1)\n",
            "Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from pylint->-r requirements.txt (line 28)) (0.13.2)\n",
            "Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->-r requirements.txt (line 29)) (3.4.0)\n",
            "Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->-r requirements.txt (line 29)) (2.6.3)\n",
            "Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from pre-commit->-r requirements.txt (line 29)) (1.9.1)\n",
            "Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/dist-packages (from pre-commit->-r requirements.txt (line 29)) (20.28.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 33)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 33)) (2.18.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python->-r requirements.txt (line 34)) (1.0.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->-r requirements.txt (line 35)) (2024.9.20)\n",
            "Requirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 36)) (2.10.3)\n",
            "Requirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 36)) (0.0.19)\n",
            "Requirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 36)) (0.2.0)\n",
            "Requirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->-r requirements.txt (line 36)) (4.10.0.84)\n",
            "Requirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations->-r requirements.txt (line 36)) (3.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 37)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 37)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 37)) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 37)) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 37)) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->-r requirements.txt (line 37)) (2.8.2)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro->-r requirements.txt (line 39)) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro->-r requirements.txt (line 39)) (1.7.1)\n",
            "Requirement already satisfied: typeguard>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from tyro->-r requirements.txt (line 39)) (4.4.1)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (3.7.1)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.115.6)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.5.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (1.5.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.28.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (3.10.12)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.0.19)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.8.3)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.41.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.15.1)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio->-r requirements.txt (line 40)) (0.33.0)\n",
            "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.5.2->gradio->-r requirements.txt (line 40)) (14.1)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow->-r requirements.txt (line 11)) (1.3.8)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 40)) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 40)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio->-r requirements.txt (line 40)) (1.2.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from docker<8,>=4.0.0->mlflow->-r requirements.txt (line 11)) (2.2.3)\n",
            "Requirement already satisfied: Werkzeug>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 11)) (3.1.3)\n",
            "Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 11)) (2.2.0)\n",
            "Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from Flask<4->mlflow->-r requirements.txt (line 11)) (1.9.0)\n",
            "Requirement already satisfied: graphql-core<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow->-r requirements.txt (line 11)) (3.2.5)\n",
            "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /usr/local/lib/python3.10/dist-packages (from graphene<4->mlflow->-r requirements.txt (line 11)) (3.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 40)) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio->-r requirements.txt (line 40)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio->-r requirements.txt (line 40)) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata->diffusers->-r requirements.txt (line 6)) (3.21.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 33)) (0.1.2)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa->-r requirements.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow->-r requirements.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3->mlflow->-r requirements.txt (line 11)) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->-r requirements.txt (line 36)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->-r requirements.txt (line 36)) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2->audio-separator->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow->-r requirements.txt (line 11)) (3.1.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio->-r requirements.txt (line 40)) (1.5.4)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv>=20.10.0->pre-commit->-r requirements.txt (line 29)) (0.3.9)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime-gpu->-r requirements.txt (line 17)) (10.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe[vision]->-r requirements.txt (line 10)) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax->mediapipe[vision]->-r requirements.txt (line 10)) (3.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface->-r requirements.txt (line 8)) (0.2.13)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.0->samplerate==0.1.0->audio-separator->-r requirements.txt (line 2)) (2.22)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.10/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (2.27.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (4.0.11)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (1.2.15)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.49b2 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (0.49b2)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (1.17.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (5.0.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.19.0->mlflow->-r requirements.txt (line 11)) (0.6.1)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 51 not upgraded.\n",
            "/content/JoyVASA/src/utils/dependencies/XPose/models/UniPose/ops\n",
            "running build\n",
            "running build_py\n",
            "copying modules/__init__.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/ms_deform_attn_key_aware.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "copying modules/ms_deform_attn.py -> build/lib.linux-x86_64-cpython-310/modules\n",
            "copying functions/__init__.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "copying functions/ms_deform_attn_func.py -> build/lib.linux-x86_64-cpython-310/functions\n",
            "running build_ext\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:495: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:414: UserWarning: The detected CUDA version (12.2) has a minor version mismatch with the version that was used to compile PyTorch (12.1). Most likely this shouldn't be a problem.\n",
            "  warnings.warn(CUDA_MISMATCH_WARN.format(cuda_str_version, torch.version.cuda))\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:424: UserWarning: There are no x86_64-linux-gnu-g++ version bounds defined for CUDA version 12.2\n",
            "  warnings.warn(f'There are no {compiler_name} version bounds defined for CUDA version {cuda_str_version}')\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer or other\n",
            "        standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "writing MultiScaleDeformableAttention.egg-info/PKG-INFO\n",
            "writing dependency_links to MultiScaleDeformableAttention.egg-info/dependency_links.txt\n",
            "writing top-level names to MultiScaleDeformableAttention.egg-info/top_level.txt\n",
            "reading manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "writing manifest file 'MultiScaleDeformableAttention.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/__init__.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn_key_aware.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/modules/ms_deform_attn.py -> build/bdist.linux-x86_64/egg/modules\n",
            "copying build/lib.linux-x86_64-cpython-310/MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/__init__.py -> build/bdist.linux-x86_64/egg/functions\n",
            "copying build/lib.linux-x86_64-cpython-310/functions/ms_deform_attn_func.py -> build/bdist.linux-x86_64/egg/functions\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn_key_aware.py to ms_deform_attn_key_aware.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/modules/ms_deform_attn.py to ms_deform_attn.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/__init__.py to __init__.cpython-310.pyc\n",
            "byte-compiling build/bdist.linux-x86_64/egg/functions/ms_deform_attn_func.py to ms_deform_attn_func.cpython-310.pyc\n",
            "creating stub loader for MultiScaleDeformableAttention.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/MultiScaleDeformableAttention.py to MultiScaleDeformableAttention.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying MultiScaleDeformableAttention.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.MultiScaleDeformableAttention.cpython-310: module references __file__\n",
            "modules.__pycache__.ms_deform_attn.cpython-310: module references __file__\n",
            "creating 'dist/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "removing '/usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg' (and everything under it)\n",
            "creating /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Extracting MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg to /usr/local/lib/python3.10/dist-packages\n",
            "Adding MultiScaleDeformableAttention 1.0 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.10/dist-packages/MultiScaleDeformableAttention-1.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "Finished processing dependencies for MultiScaleDeformableAttention==1.0\n",
            "/content/JoyVASA\n",
            "Fetching 11 files: 100% 11/11 [00:00<00:00, 8122.77it/s]\n",
            "Snapshot downloaded to: /content/JoyVASA/pretrained_weights/wav2vec2-base-960h\n",
            "Fetching 6 files:   0% 0/6 [00:00<?, ?it/s]\n",
            "config.json: 100% 1.38k/1.38k [00:00<00:00, 9.76MB/s]\n",
            "\n",
            ".gitattributes: 100% 1.17k/1.17k [00:00<00:00, 11.9MB/s]\n",
            "Fetching 6 files:  17% 1/6 [00:00<00:01,  4.80it/s]\n",
            "preprocessor_config.json: 100% 212/212 [00:00<00:00, 2.09MB/s]\n",
            "\n",
            "chinese-hubert-base-fairseq-ckpt.pt:   0% 0.00/1.14G [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "README.md: 100% 1.19k/1.19k [00:00<00:00, 9.58MB/s]\n",
            "\n",
            "\n",
            "pytorch_model.bin:   0% 0.00/378M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "pytorch_model.bin:   3% 10.5M/378M [00:00<00:03, 99.1MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:   2% 21.0M/1.14G [00:00<00:07, 146MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:   8% 31.5M/378M [00:00<00:02, 155MB/s] \u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:   5% 52.4M/1.14G [00:00<00:05, 199MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  17% 62.9M/378M [00:00<00:01, 178MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:   6% 73.4M/1.14G [00:00<00:05, 186MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  22% 83.9M/378M [00:00<00:01, 169MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:   8% 94.4M/1.14G [00:00<00:05, 177MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  28% 105M/378M [00:00<00:01, 152MB/s] \u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  10% 115M/1.14G [00:00<00:06, 155MB/s] \u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  12% 136M/1.14G [00:00<00:06, 157MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  33% 126M/378M [00:00<00:01, 142MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  14% 157M/1.14G [00:00<00:06, 148MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  39% 147M/378M [00:01<00:01, 137MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  16% 178M/1.14G [00:01<00:06, 151MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  44% 168M/378M [00:01<00:01, 138MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  18% 199M/1.14G [00:01<00:06, 140MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  50% 189M/378M [00:01<00:01, 133MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  19% 220M/1.14G [00:01<00:06, 137MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  56% 210M/378M [00:01<00:01, 130MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  21% 241M/1.14G [00:01<00:06, 132MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  61% 231M/378M [00:01<00:01, 129MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  23% 262M/1.14G [00:01<00:06, 130MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  67% 252M/378M [00:01<00:00, 126MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  25% 283M/1.14G [00:01<00:06, 127MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  72% 273M/378M [00:02<00:00, 118MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  27% 304M/1.14G [00:02<00:06, 119MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  78% 294M/378M [00:02<00:00, 115MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  29% 325M/1.14G [00:02<00:06, 124MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  83% 315M/378M [00:02<00:00, 118MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  30% 346M/1.14G [00:02<00:06, 121MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  89% 336M/378M [00:02<00:00, 118MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  32% 367M/1.14G [00:02<00:06, 125MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin:  94% 357M/378M [00:02<00:00, 116MB/s]\u001b[A\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  34% 388M/1.14G [00:02<00:06, 122MB/s]\u001b[A\n",
            "\n",
            "pytorch_model.bin: 100% 378M/378M [00:02<00:00, 126MB/s]\n",
            "\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  36% 409M/1.14G [00:03<00:05, 122MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  39% 440M/1.14G [00:03<00:04, 151MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  42% 472M/1.14G [00:03<00:04, 164MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  43% 493M/1.14G [00:03<00:03, 170MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  45% 514M/1.14G [00:03<00:03, 178MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  48% 545M/1.14G [00:03<00:03, 192MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  50% 566M/1.14G [00:03<00:03, 188MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  53% 598M/1.14G [00:03<00:02, 204MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  55% 629M/1.14G [00:04<00:02, 215MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  58% 661M/1.14G [00:04<00:02, 199MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  60% 682M/1.14G [00:04<00:02, 198MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  62% 703M/1.14G [00:04<00:02, 187MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  64% 724M/1.14G [00:04<00:02, 187MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  66% 744M/1.14G [00:04<00:02, 182MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  68% 776M/1.14G [00:04<00:01, 187MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  70% 797M/1.14G [00:04<00:01, 191MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  73% 828M/1.14G [00:05<00:01, 209MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  76% 860M/1.14G [00:05<00:01, 220MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  78% 891M/1.14G [00:05<00:01, 232MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  81% 923M/1.14G [00:05<00:00, 226MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  84% 954M/1.14G [00:05<00:00, 213MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  87% 986M/1.14G [00:05<00:00, 227MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  89% 1.02G/1.14G [00:05<00:00, 237MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  92% 1.05G/1.14G [00:06<00:01, 80.0MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  95% 1.08G/1.14G [00:06<00:00, 102MB/s] \u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt:  98% 1.11G/1.14G [00:07<00:00, 122MB/s]\u001b[A\n",
            "chinese-hubert-base-fairseq-ckpt.pt: 100% 1.14G/1.14G [00:07<00:00, 157MB/s]\n",
            "Fetching 6 files: 100% 6/6 [00:07<00:00,  1.25s/it]\n",
            "Snapshot downloaded to: /content/JoyVASA/pretrained_weights/TencentGameMate:chinese-hubert-base\n",
            "Fetching 20 files:   0% 0/20 [00:00<?, ?it/s]\n",
            ".gitignore: 100% 254/254 [00:00<00:00, 1.66MB/s]\n",
            "\n",
            "README.md: 100% 12.5k/12.5k [00:00<00:00, 62.3MB/s]\n",
            "\n",
            "inference.gif:   0% 0.00/820k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            ".gitattributes: 100% 2.83k/2.83k [00:00<00:00, 20.8MB/s]\n",
            "Fetching 20 files:   5% 1/20 [00:00<00:04,  4.28it/s]\n",
            "\n",
            "inference.gif: 100% 820k/820k [00:00<00:00, 18.0MB/s]\n",
            "\n",
            "det_10g.onnx:   0% 0.00/16.9M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "showcase2.gif: 100% 2.88M/2.88M [00:00<00:00, 37.8MB/s]\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth:   0% 0.00/3.39M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "2d106det.onnx: 100% 5.03M/5.03M [00:00<00:00, 37.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "2d106det.onnx: 100% 5.03M/5.03M [00:00<00:00, 36.3MB/s]\n",
            "Fetching 20 files:  35% 7/20 [00:00<00:00, 19.31it/s]\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth: 100% 3.39M/3.39M [00:00<00:00, 35.9MB/s]\n",
            "\n",
            "\n",
            "landmark.onnx:   0% 0.00/115M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   0% 0.00/182M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "det_10g.onnx:  62% 10.5M/16.9M [00:00<00:00, 38.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "stitching_retargeting_module.pth: 100% 2.39M/2.39M [00:00<00:00, 43.7MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth:   0% 0.00/3.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   0% 0.00/113M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "det_10g.onnx: 100% 16.9M/16.9M [00:00<00:00, 41.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "det_10g.onnx: 100% 16.9M/16.9M [00:00<00:00, 38.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   9% 10.5M/113M [00:00<00:02, 36.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:   9% 10.5M/115M [00:00<00:02, 40.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth: 100% 3.39M/3.39M [00:00<00:00, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "appearance_feature_extractor.pth: 100% 3.39M/3.39M [00:00<00:00, 28.3MB/s]\n",
            "\n",
            "spade_generator.pth:   0% 0.00/222M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "stitching_retargeting_module.pth:   0% 0.00/2.39M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:   9% 10.5M/113M [00:00<00:02, 42.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  19% 21.0M/113M [00:00<00:02, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   0% 0.00/182M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "stitching_retargeting_module.pth: 100% 2.39M/2.39M [00:00<00:00, 20.7MB/s]\n",
            "\n",
            "\n",
            "landmark.onnx:  18% 21.0M/115M [00:00<00:02, 39.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  12% 21.0M/182M [00:00<00:04, 40.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:   5% 10.5M/222M [00:00<00:06, 35.0MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  28% 31.5M/113M [00:00<00:01, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  19% 21.0M/113M [00:00<00:02, 38.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  14% 31.5M/222M [00:00<00:04, 41.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  27% 31.5M/115M [00:00<00:02, 39.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  17% 31.5M/182M [00:00<00:03, 39.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   0% 0.00/435M [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:   6% 10.5M/182M [00:00<00:04, 34.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:   9% 21.0M/222M [00:00<00:05, 38.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  28% 31.5M/113M [00:00<00:02, 38.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  37% 41.9M/113M [00:01<00:01, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  37% 41.9M/115M [00:01<00:01, 41.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  23% 41.9M/182M [00:01<00:03, 40.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   2% 10.5M/435M [00:00<00:11, 37.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  12% 21.0M/182M [00:00<00:04, 37.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  14% 31.5M/222M [00:00<00:04, 45.2MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  37% 41.9M/113M [00:01<00:01, 43.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  19% 41.9M/222M [00:01<00:05, 30.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  47% 52.4M/113M [00:01<00:01, 43.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  46% 52.4M/115M [00:01<00:01, 38.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   5% 21.0M/435M [00:00<00:11, 36.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  17% 31.5M/182M [00:00<00:04, 36.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  47% 52.4M/113M [00:01<00:01, 44.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  29% 52.4M/182M [00:01<00:03, 35.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  19% 41.9M/222M [00:01<00:04, 41.4MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  56% 62.9M/113M [00:01<00:01, 43.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  24% 52.4M/222M [00:01<00:05, 33.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  55% 62.9M/115M [00:01<00:01, 41.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:   7% 31.5M/435M [00:00<00:09, 43.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  23% 41.9M/182M [00:01<00:03, 40.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  56% 62.9M/113M [00:01<00:01, 43.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  35% 62.9M/182M [00:01<00:03, 36.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  24% 52.4M/222M [00:01<00:04, 40.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  28% 62.9M/222M [00:01<00:04, 35.4MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  65% 73.4M/113M [00:01<00:00, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  64% 73.4M/115M [00:01<00:00, 44.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  10% 41.9M/435M [00:01<00:09, 42.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  29% 52.4M/182M [00:01<00:02, 43.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  28% 62.9M/222M [00:01<00:03, 43.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  65% 73.4M/113M [00:01<00:00, 43.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  40% 73.4M/182M [00:01<00:02, 38.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  33% 73.4M/222M [00:02<00:03, 37.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  73% 83.9M/115M [00:01<00:00, 45.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  75% 83.9M/113M [00:02<00:00, 41.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  35% 62.9M/182M [00:01<00:02, 45.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  12% 52.4M/435M [00:01<00:08, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  40% 73.4M/182M [00:01<00:02, 47.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  46% 83.9M/182M [00:02<00:02, 35.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  33% 73.4M/222M [00:01<00:04, 36.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  14% 62.9M/435M [00:01<00:08, 43.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  82% 94.4M/115M [00:02<00:00, 36.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  84% 94.4M/113M [00:02<00:00, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  46% 83.9M/182M [00:01<00:02, 45.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  38% 83.9M/222M [00:02<00:04, 29.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  75% 83.9M/113M [00:02<00:00, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  17% 73.4M/435M [00:01<00:08, 43.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  52% 94.4M/182M [00:02<00:02, 34.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  38% 83.9M/222M [00:02<00:04, 33.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  93% 105M/113M [00:02<00:00, 36.3MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  84% 94.4M/113M [00:02<00:00, 33.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  52% 94.4M/182M [00:02<00:01, 44.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx:  91% 105M/115M [00:02<00:00, 34.1MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  58% 105M/182M [00:02<00:02, 37.1MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  43% 94.4M/222M [00:02<00:04, 29.8MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  43% 94.4M/222M [00:02<00:03, 34.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:03<00:00, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  58% 105M/182M [00:02<00:02, 36.5MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "landmark.onnx: 100% 115M/115M [00:09<00:00, 4.71MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth:  93% 105M/113M [00:09<00:01, 4.71MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:10<00:00, 11.1MB/s]\n",
            "landmark.onnx: 100% 115M/115M [00:10<00:00, 11.4MB/s]\n",
            "Fetching 20 files:  50% 10/20 [00:10<00:13,  1.35s/it]\n",
            "spade_generator.pth:  47% 105M/222M [00:09<00:27, 4.31MB/s] \u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:09<00:00, 5.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  63% 115M/182M [00:10<00:15, 4.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  47% 105M/222M [00:10<00:27, 4.19MB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  22% 94.4M/435M [00:09<01:00, 5.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "motion_extractor.pth: 100% 113M/113M [00:10<00:00, 11.2MB/s]\n",
            "\n",
            "spade_generator.pth:  52% 115M/222M [00:09<00:17, 6.07MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  24% 105M/435M [00:09<00:41, 7.86MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  69% 126M/182M [00:09<00:09, 6.24MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  69% 126M/182M [00:10<00:09, 5.88MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  52% 115M/222M [00:10<00:18, 5.74MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  75% 136M/182M [00:09<00:05, 8.62MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  27% 115M/435M [00:09<00:29, 10.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  61% 136M/222M [00:10<00:08, 10.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  81% 147M/182M [00:10<00:03, 11.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  81% 147M/182M [00:10<00:03, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  29% 126M/435M [00:09<00:22, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  61% 136M/222M [00:10<00:08, 10.1MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  86% 157M/182M [00:10<00:01, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  86% 157M/182M [00:10<00:01, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  66% 147M/222M [00:10<00:06, 12.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  31% 136M/435M [00:10<00:17, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  66% 147M/222M [00:11<00:06, 12.5MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  92% 168M/182M [00:10<00:00, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  34% 147M/435M [00:10<00:12, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  92% 168M/182M [00:11<00:00, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  71% 157M/222M [00:11<00:04, 15.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  76% 168M/222M [00:10<00:02, 18.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  34% 147M/435M [00:21<00:12, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  71% 157M/222M [00:21<00:04, 15.3MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  76% 168M/222M [00:21<00:02, 18.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  92% 168M/182M [00:21<00:00, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  92% 168M/182M [00:21<00:00, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  98% 178M/182M [00:22<00:01, 2.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  36% 157M/435M [00:23<01:53, 2.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  36% 157M/435M [00:41<01:53, 2.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  98% 178M/182M [00:41<00:01, 2.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth:  98% 178M/182M [00:43<00:03, 1.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  76% 168M/222M [00:49<00:56, 960kB/s] \u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth: 100% 182M/182M [01:00<00:00, 600kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "warping_module.pth: 100% 182M/182M [01:00<00:00, 3.00MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "warping_module.pth: 100% 182M/182M [01:01<00:00, 2.97MB/s]\n",
            "\n",
            "spade_generator.pth:  85% 189M/222M [01:00<00:28, 1.17MB/s]\u001b[A\n",
            "spade_generator.pth:  90% 199M/222M [01:01<00:14, 1.57MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  39% 168M/435M [01:00<06:01, 739kB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  80% 178M/222M [01:01<00:46, 931kB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  85% 189M/222M [01:01<00:25, 1.30MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth:  95% 210M/222M [01:01<00:05, 2.13MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  43% 189M/435M [01:00<03:00, 1.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  90% 199M/222M [01:01<00:12, 1.82MB/s]\u001b[A\u001b[A\u001b[A\n",
            "spade_generator.pth: 100% 222M/222M [01:01<00:00, 3.60MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  46% 199M/435M [01:01<02:11, 1.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth:  95% 210M/222M [01:02<00:04, 2.53MB/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  48% 210M/435M [01:01<01:34, 2.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "spade_generator.pth: 100% 222M/222M [01:02<00:00, 3.56MB/s]\n",
            "Fetching 20 files:  55% 11/20 [01:02<01:23,  9.32s/it]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  51% 220M/435M [01:01<01:06, 3.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  53% 231M/435M [01:01<00:47, 4.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  55% 241M/435M [01:02<00:33, 5.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  58% 252M/435M [01:02<00:23, 7.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  60% 262M/435M [01:02<00:16, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  63% 273M/435M [01:02<00:12, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  65% 283M/435M [01:03<00:09, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  67% 294M/435M [01:03<00:06, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  70% 304M/435M [01:03<00:05, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  72% 315M/435M [01:03<00:04, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  75% 325M/435M [01:04<00:03, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  77% 336M/435M [01:04<00:02, 33.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  80% 346M/435M [01:04<00:02, 35.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  82% 357M/435M [01:04<00:02, 37.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  84% 367M/435M [01:05<00:01, 39.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  87% 377M/435M [01:05<00:01, 39.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  89% 388M/435M [01:05<00:01, 40.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  92% 398M/435M [01:05<00:00, 41.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  94% 409M/435M [01:06<00:00, 41.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  96% 419M/435M [01:06<00:00, 41.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth:  99% 430M/435M [01:06<00:00, 41.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "xpose.pth: 100% 435M/435M [01:06<00:00, 6.52MB/s]\n",
            "Fetching 20 files: 100% 20/20 [01:08<00:00,  3.40s/it]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n!python inference.py -r assets/examples/imgs/joyvasa_001.png -a assets/examples/audio/joyvasa_001.wav --animation_mode animal --cfg_scale 2.0\\n\\n!python inference.py -r assets/examples/imgs/joyvasa_002.png -a assets/examples/audio/joyvasa_001.wav --animation_mode animal --cfg_scale 2.0\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "\n",
        "!git clone https://github.com/SebastienPaviot/JoyVASA.git\n",
        "%cd JoyVASA\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "\n",
        "!sudo apt-get update\n",
        "!sudo apt-get install ffmpeg -y\n",
        "\n",
        "\n",
        "%cd src/utils/dependencies/XPose/models/UniPose/ops\n",
        "!python setup.py build install\n",
        "\n",
        "%cd /content/JoyVASA/\n",
        "!python download_model.py\n",
        "\n",
        "\n",
        "'''\n",
        "!python inference.py -r assets/examples/imgs/joyvasa_001.png -a assets/examples/audio/joyvasa_001.wav --animation_mode animal --cfg_scale 2.0\n",
        "\n",
        "!python inference.py -r assets/examples/imgs/joyvasa_002.png -a assets/examples/audio/joyvasa_001.wav --animation_mode animal --cfg_scale 2.0\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py -r assets/examples/imgs/tai.jpg -a assets/examples/audio/record.wav --animation_mode animal --cfg_scale 2.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKpsZ5SeYqsc",
        "outputId": "d61f1156-0d7a-4a88-aaba-22ec10c6c316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/inference.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py -r assets/examples/imgs/4.png -a assets/examples/audio/joyvasa_001.wav --animation_mode human --cfg_scale 2.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kqYRgxQX2RIx",
        "outputId": "e9a1a0a9-2634-4814-8265-cf2e92c316ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/JoyVASA/src/utils/helper.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location=lambda storage, loc: storage))\n",
            "\u001b[2;36m[20:49:05]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from                    \u001b]8;id=906620;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=570680;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mappearance_feature_extractor.pth\u001b[0m done.                \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m[20:49:06]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                                \u001b]8;id=33227;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=568029;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#58\u001b\\\u001b[2m58\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mmotion_extractor.pth\u001b[0m done.                            \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m[20:49:07]\u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                                  \u001b]8;id=661900;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=27076;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mwarping_module.pth\u001b[0m done.                              \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m[20:49:08]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                                 \u001b]8;id=240977;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=303512;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#64\u001b\\\u001b[2m64\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mspade_generator.pth\u001b[0m done.                             \u001b[2m                               \u001b[0m\n",
            "/content/JoyVASA/src/utils/helper.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from                    \u001b]8;id=13101;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=326654;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#68\u001b\\\u001b[2m68\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/retarget\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35ming_models/\u001b[0m\u001b[95mstitching_retargeting_module.pth\u001b[0m done.         \u001b[2m                               \u001b[0m\n",
            "/content/JoyVASA/src/utils/helper.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_data = torch.load(ckpt_path, map_location=device)\n",
            "using hubert chinese ori\n",
            "2024-12-07 20:49:10.669569: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-07 20:49:10.685891: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-07 20:49:10.690516: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-07 20:49:10.703417: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-07 20:49:11.932293: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2;36m[20:49:13]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_generator from                                \u001b]8;id=570649;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=310923;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/JoyVASA/motion_genera\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mtor/\u001b[0m\u001b[95mmotion_generator_hubert_chinese.pt\u001b[0m done.              \u001b[2m                               \u001b[0m\n",
            "\u001b[1;31m2024-12-07 20:49:13.522344327 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn_adv.so.9: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2024-12-07 20:49:13.546140763 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn_adv.so.9: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m217s                               \u001b]8;id=662781;file:///content/JoyVASA/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=338306;file:///content/JoyVASA/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2024-12-07 20:49:13.859234654 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn_adv.so.9: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m[20:49:14]\u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m136s                            \u001b]8;id=460047;file:///content/JoyVASA/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=740568;file:///content/JoyVASA/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad reference image from assets/examples/imgs/\u001b[1;36m4.\u001b[0mpng     \u001b]8;id=367935;file:///content/JoyVASA/src/live_portrait_wmg_pipeline.py\u001b\\\u001b[2mlive_portrait_wmg_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=722662;file:///content/JoyVASA/src/live_portrait_wmg_pipeline.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mstart loading audio from                                 \u001b]8;id=535982;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=469788;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#361\u001b\\\u001b[2m361\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0massets/examples/audio/joyvasa_001.wav                    \u001b[2m                                \u001b[0m\n",
            "\u001b[2;36m[20:49:15]\u001b[0m\u001b[2;36m \u001b[0maudio loaded! \u001b[1m(\u001b[0m\u001b[1;36m319878\u001b[0m,\u001b[1m)\u001b[0m                                  \u001b]8;id=87566;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=960713;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#363\u001b\\\u001b[2m363\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mloading audio from:                                      \u001b]8;id=853205;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=826399;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#369\u001b\\\u001b[2m369\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0massets/examples/audio/joyvasa_001.wav                    \u001b[2m                                \u001b[0m\n",
            "HubertModel is using HubertSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "\u001b[2KGenerating Motion Sequence... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:00\u001b[0m\n",
            "\u001b[2KAnimating Image with Generated Motions... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:02:23\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:08\u001b[0m\n",
            "\u001b[1A\u001b[2Kaudio:  assets/examples/audio/joyvasa_001.wav\n",
            "\u001b[2;36m[20:52:01]\u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                                     \u001b]8;id=825915;file:///content/JoyVASA/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=131260;file:///content/JoyVASA/src/utils/video.py#218\u001b\\\u001b[2m218\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/animations/\u001b[0m\u001b[95m4_joyvasa_001.mp4\u001b[0m                                \u001b[2m            \u001b[0m\n",
            "/content/JoyVASA/animations/4_joyvasa_001.mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: ask to upload 2 files the fist in png or jpg format and the second in wav format) and keep the absolute paths in 2 variables\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "uploaded_image = files.upload()\n",
        "image_path = list(uploaded_image.keys())[0]\n",
        "\n",
        "uploaded_audio = files.upload()\n",
        "audio_path = list(uploaded_audio.keys())[0]\n",
        "\n",
        "print(f\"Image path: {image_path}\")\n",
        "print(f\"Audio path: {audio_path}\")\n",
        "\n",
        "!python inference.py -r \"{image_path}\" -a \"{audio_path}\" --animation_mode human --cfg_scale 1.0\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "RqEHpmhAEvOF",
        "outputId": "466dbcd0-a87b-4f5e-fb69-32b22e062167"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d3365f25-95fc-4d55-8477-c1cd794e30aa\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d3365f25-95fc-4d55-8477-c1cd794e30aa\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving e184c037-2a1e-44aa-bc9b-c67863f8de1d-removebg-preview.png to e184c037-2a1e-44aa-bc9b-c67863f8de1d-removebg-preview.png\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f37033da-f198-40a9-b122-891ef02d457c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f37033da-f198-40a9-b122-891ef02d457c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving download (2).wav to download (2).wav\n",
            "Image path: e184c037-2a1e-44aa-bc9b-c67863f8de1d-removebg-preview.png\n",
            "Audio path: download (2).wav\n",
            "/content/JoyVASA/src/utils/helper.py:207: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(ckpt_path, map_location=lambda storage, loc: storage))\n",
            "\u001b[2;36m[21:20:59]\u001b[0m\u001b[2;36m \u001b[0mLoad appearance_feature_extractor from                    \u001b]8;id=285331;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=653452;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#55\u001b\\\u001b[2m55\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mappearance_feature_extractor.pth\u001b[0m done.                \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m[21:21:00]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_extractor from                                \u001b]8;id=859632;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=365906;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#58\u001b\\\u001b[2m58\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mmotion_extractor.pth\u001b[0m done.                            \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad warping_module from                                  \u001b]8;id=774681;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=619796;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#61\u001b\\\u001b[2m61\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mwarping_module.pth\u001b[0m done.                              \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m[21:21:01]\u001b[0m\u001b[2;36m \u001b[0mLoad spade_generator from                                 \u001b]8;id=205334;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=130991;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#64\u001b\\\u001b[2m64\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/base_mod\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mels/\u001b[0m\u001b[95mspade_generator.pth\u001b[0m done.                             \u001b[2m                               \u001b[0m\n",
            "/content/JoyVASA/src/utils/helper.py:182: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(ckpt_path, map_location=lambda storage, loc: storage)\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad stitching_retargeting_module from                    \u001b]8;id=214271;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=536602;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#68\u001b\\\u001b[2m68\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/liveportrait/retarget\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35ming_models/\u001b[0m\u001b[95mstitching_retargeting_module.pth\u001b[0m done.         \u001b[2m                               \u001b[0m\n",
            "/content/JoyVASA/src/utils/helper.py:161: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_data = torch.load(ckpt_path, map_location=device)\n",
            "using hubert chinese ori\n",
            "The cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\n",
            "0it [00:00, ?it/s]\n",
            "2024-12-14 21:21:08.796922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-12-14 21:21:08.814159: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-12-14 21:21:08.819726: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-12-14 21:21:08.831910: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-12-14 21:21:10.468386: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[2;36m[21:21:13]\u001b[0m\u001b[2;36m \u001b[0mLoad motion_generator from                                \u001b]8;id=547708;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=35947;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#82\u001b\\\u001b[2m82\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/pretrained_weights/JoyVASA/motion_genera\u001b[0m \u001b[2m                               \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[35mtor/\u001b[0m\u001b[95mmotion_generator_hubert_chinese.pt\u001b[0m done.              \u001b[2m                               \u001b[0m\n",
            "\u001b[1;31m2024-12-14 21:21:13.161779822 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn_adv.so.9: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[1;31m2024-12-14 21:21:13.219119492 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn_adv.so.9: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mFaceAnalysisDIY warmup time: \u001b[1;36m0.\u001b[0m276s                               \u001b]8;id=955779;file:///content/JoyVASA/src/utils/face_analysis_diy.py\u001b\\\u001b[2mface_analysis_diy.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=466239;file:///content/JoyVASA/src/utils/face_analysis_diy.py#79\u001b\\\u001b[2m79\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[1;31m2024-12-14 21:21:13.596309603 [E:onnxruntime:Default, provider_bridge_ort.cc:1862 TryGetProviderInfo_CUDA] /onnxruntime_src/onnxruntime/core/session/provider_bridge_ort.cc:1539 onnxruntime::Provider& onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcudnn_adv.so.9: cannot open shared object file: No such file or directory\n",
            "\u001b[m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLandmarkRunner warmup time: \u001b[1;36m0.\u001b[0m152s                            \u001b]8;id=341331;file:///content/JoyVASA/src/utils/human_landmark_runner.py\u001b\\\u001b[2mhuman_landmark_runner.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=457828;file:///content/JoyVASA/src/utils/human_landmark_runner.py#95\u001b\\\u001b[2m95\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mLoad reference image from                                \u001b]8;id=315890;file:///content/JoyVASA/src/live_portrait_wmg_pipeline.py\u001b\\\u001b[2mlive_portrait_wmg_pipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=321511;file:///content/JoyVASA/src/live_portrait_wmg_pipeline.py#46\u001b\\\u001b[2m46\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[93me184c037-2a1e-44aa-bc9b-c67863f8de1d\u001b[0m-removebg-preview.pn \u001b[2m                                \u001b[0m\n",
            "\u001b[2;36m           \u001b[0mg                                                        \u001b[2m                                \u001b[0m\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mstart loading audio from download \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m.wav                \u001b]8;id=254252;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=898947;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#361\u001b\\\u001b[2m361\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m[21:21:27]\u001b[0m\u001b[2;36m \u001b[0maudio loaded! \u001b[1m(\u001b[0m\u001b[1;36m1470720\u001b[0m,\u001b[1m)\u001b[0m                                 \u001b]8;id=875000;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=353166;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#363\u001b\\\u001b[2m363\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m          \u001b[0m\u001b[2;36m \u001b[0mloading audio from: download \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m.wav                     \u001b]8;id=397540;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py\u001b\\\u001b[2mlive_portrait_wmg_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=395194;file:///content/JoyVASA/src/live_portrait_wmg_wrapper.py#369\u001b\\\u001b[2m369\u001b[0m\u001b]8;;\u001b\\\n",
            "HubertModel is using HubertSdpaAttention, but `torch.nn.functional.scaled_dot_product_attention` does not support `output_attentions=True` or `layer_head_mask` not None. Falling back to the manual attention implementation, but specifying the manual implementation will be required from Transformers version v5.0.0 onwards. This warning can be removed using the argument `attn_implementation=\"eager\"` when loading the model.\n",
            "\u001b[2KGenerating Motion Sequence... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:03\u001b[0m\n",
            "\u001b[2KAnimating Image with Generated Motions... \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:10:29\u001b[0m\n",
            "\u001b[2KWriting \u001b[90m\u001b[0m \u001b[35m100%\u001b[0m \u001b[33m0:00:26\u001b[0m\n",
            "\u001b[1A\u001b[2Kaudio:  download \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m.wav\n",
            "\u001b[2;36m[21:33:12]\u001b[0m\u001b[2;36m \u001b[0mVideo with audio generated successfully:                                     \u001b]8;id=480597;file:///content/JoyVASA/src/utils/video.py\u001b\\\u001b[2mvideo.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=440196;file:///content/JoyVASA/src/utils/video.py#218\u001b\\\u001b[2m218\u001b[0m\u001b]8;;\u001b\\\n",
            "\u001b[2;36m           \u001b[0m\u001b[35m/content/JoyVASA/animations/\u001b[0m\u001b[95me184c037-2a1e-44aa-bc9b-c67863f8de1d-removebg-pr\u001b[0m \u001b[2m            \u001b[0m\n",
            "\u001b[2;36m           \u001b[0m\u001b[95meview_download\u001b[0m \u001b[1m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m.mp4                                                       \u001b[2m            \u001b[0m\n",
            "/content/JoyVASA/animations/e184c037-2a1e-44aa-bc9b-c67863f8de1d-removebg-preview_download (2).mp4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python inference.py -r \"{image_path}\" -a \"{audio_path}\" --animation_mode human --cfg_scale 1.0\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPUYEQ7vOV9w",
        "outputId": "be826d5c-0113-4934-cbb6-e061bf467eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/JoyVASA/inference.py\", line 74, in <module>\n",
            "    main()\n",
            "  File \"/content/JoyVASA/inference.py\", line 46, in main\n",
            "    fast_check_args(args)\n",
            "  File \"/content/JoyVASA/inference.py\", line 28, in fast_check_args\n",
            "    raise FileNotFoundError(f\"reference info not found: {args.reference}\")\n",
            "FileNotFoundError: reference info not found: {image_path}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n",
        "import os\n",
        "\n",
        "def add_text_to_video(input_video: str, output_video: str, text: str = \"Franois Bayrou\"):\n",
        "    \"\"\"\n",
        "    Ajoute un texte centr  droite sur une vido.\n",
        "\n",
        "    Args:\n",
        "        input_video (str): Chemin vers la vido d'entre.\n",
        "        output_video (str): Chemin o la vido gnre sera sauvegarde.\n",
        "        text (str): Texte  afficher (par dfaut : \"Franois Bayrou\").\n",
        "    \"\"\"\n",
        "    # Vrifier si le fichier d'entre existe\n",
        "    if not os.path.isfile(input_video):\n",
        "        raise FileNotFoundError(f\"La vido d'entre '{input_video}' est introuvable.\")\n",
        "\n",
        "    # Commande FFmpeg pour ajouter du texte\n",
        "    cmd = [\n",
        "        \"ffmpeg\",\n",
        "        \"-i\", input_video,  # Fichier d'entre\n",
        "        \"-vf\", f\"drawtext=text='{text}':fontcolor=white:fontsize=48:x=w-tw-10:y=(h-text_h)/2\",  # Texte centr  droite\n",
        "        \"-codec:a\", \"copy\",  # Ne pas rencoder l'audio\n",
        "        output_video  # Fichier de sortie\n",
        "    ]\n",
        "\n",
        "    # Excuter la commande\n",
        "    subprocess.run(cmd, check=True)\n",
        "\n",
        "# Exemple d'utilisation\n",
        "add_text_to_video(\"animations/emmanuel.mp4\", \"output.mp4\",\"Emmanuel Macron\")"
      ],
      "metadata": {
        "id": "v5BriYuf9Q4R"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}